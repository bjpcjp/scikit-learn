{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Regression Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n",
    "\n",
    "- `multiword` controls how scores or losses are calculated:\n",
    "    - 'uniform_average' (default): uses a uniform mean.\n",
    "    - `ndarray of (weights)`: weighted average\n",
    "    - 'raw_values': unchanged values returned as an array\n",
    "    \n",
    "- `r2_score` and `explained_variance_score` also accept `multioutput=\"variance_weighted\"` for weighing the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Explained Variance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)\n",
    "\n",
    "- $explained\\_{}variance(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}$.\n",
    "\n",
    "- 1.0 is best possible score. Lower numbers are worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571734475374732\n",
      "[0.96774194 1.        ]\n",
      "0.9903225806451612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score as EVS\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "print(EVS(y_true, y_pred))\n",
    "\n",
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0,   2], [-1, 2], [8, -5]]\n",
    "\n",
    "print(EVS(y_true, y_pred, multioutput='raw_values'))\n",
    "print(EVS(y_true, y_pred, multioutput=[0.3, 0.7]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Max Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error)\n",
    "\n",
    "- Returns a maximum *residual error* (between prediction and true value). Should return 0 in perfectly fitted model's training set.\n",
    "\n",
    "- $\\text{Max Error}(y, \\hat{y}) = max(| y_i - \\hat{y}_i |)$\n",
    "\n",
    "- Multioutputs are not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import max_error\n",
    "y_true = [3, 2, 7, 1]\n",
    "y_pred = [9, 2, 7, 1]\n",
    "print(max_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Mean Absolute Error (MAE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)\n",
    "\n",
    "- MAE corresponds to the expected L1-norm loss.\n",
    "\n",
    "- $\\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\left| y_i - \\hat{y}_i \\right|.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.75\n",
      "[0.5 1. ]\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "y_true = [3,  -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "print(MAE(y_true, y_pred))\n",
    "\n",
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0,   2], [-1, 2], [8, -5]]\n",
    "\n",
    "print(MAE(y_true, y_pred))\n",
    "print(MAE(y_true, y_pred, multioutput='raw_values'))\n",
    "print(MAE(y_true, y_pred, multioutput=[0.3, 0.7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Mean Squared Error (MSE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)\n",
    "\n",
    "- MSE corresponds to the expected squared (quadratic) loss.\n",
    "\n",
    "- $\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "print(MSE(y_true, y_pred))\n",
    "\n",
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0,   2], [-1, 2], [8, -5]]\n",
    "\n",
    "print(MSE(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Mean Squared Log Error (MSLE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error)\n",
    "\n",
    "- This metric is preferred when measuring *exponential growth* variables (populations, commodity sales over time, ...). It penalizes under-predicted estimates more than over-predicted ones.\n",
    "\n",
    "- $\\text{MSLE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (\\log_e (1 + y_i) - \\log_e (1 + \\hat{y}_i) )^2.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03973012298459379\n",
      "0.044199361889160516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error as MSLE\n",
    "y_true = [3, 5, 2.5, 7]\n",
    "y_pred = [2.5, 5, 4, 8]\n",
    "\n",
    "print(MSLE(y_true, y_pred))\n",
    "\n",
    "y_true = [[0.5, 1], [1, 2], [7, 6]]\n",
    "y_pred = [[0.5, 2], [1, 2.5], [8, 8]]\n",
    "\n",
    "print(MSLE(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Mean Absolute Pct Error (MAPE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error)\n",
    "\n",
    "- Also called *mean absolute percentage deviation (MAPD)*. \n",
    "\n",
    "- Sensitive to relative errors; not affected by a global scaling of the target variable.\n",
    "\n",
    "- $\\text{MAPE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\frac{{}\\left| y_i - \\hat{y}_i \\right|}{max(\\epsilon, \\left| y_i \\right|)}$\n",
    "\n",
    "- Supports multiple output problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "y_true = [1, 10, 1e6]\n",
    "y_pred = [0.9, 15, 1.2e6]\n",
    "print(MAPE(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [R^2 score (coefficient of determination)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)\n",
    "\n",
    "- Represents the proportion of variance (of y) that is explained by *the independent variables in the model*. It is an indication of *goodness of fit* - therefore, a measure of how well unseen samples are likely to be predicted by the model.\n",
    "\n",
    "- Variance is dataset dependent - so R² may not be comparable across different datasets. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R² score of 0.0.\n",
    "\n",
    "- $R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486081370449679\n",
      "0.9382566585956417\n",
      "0.9368005266622779\n",
      "[0.96543779 0.90816327]\n",
      "0.9253456221198156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score as R2\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "print(R2(y_true, y_pred))\n",
    "\n",
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0,   2], [-1, 2], [8, -5]]\n",
    "print(R2(y_true, y_pred, \n",
    "         multioutput='variance_weighted'))\n",
    "print(R2(y_true, y_pred, \n",
    "         multioutput='uniform_average'))\n",
    "print(R2(y_true, y_pred, \n",
    "         multioutput='raw_values'))\n",
    "print(R2(y_true, y_pred, \n",
    "         multioutput=[0.3, 0.7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Tweedie Deviances](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance)\n",
    "\n",
    "- Returns a mean [Tweedie deviance error](https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance) based on a `power` parameter:\n",
    "\n",
    "    - `power=0`: equivalent to MSE ([mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error))\n",
    "    - `power=1`: equivalent to MPD ([mean poisson deviance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_poisson_deviance.html#sklearn.metrics.mean_poisson_deviance)\n",
    "    - `power=2`: equivalent to MGD ([mean gamma deviance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_gamma_deviance.html#sklearn.metrics.mean_gamma_deviance)\n",
    "\n",
    "- Gamma distribution with power=2 means that simultaneously scaling y_true and y_pred has no effect on the deviance. \n",
    "\n",
    "- Poisson distribution power=1 the deviance scales linearly.\n",
    "\n",
    "- Normal distribution (power=0), quadratically. \n",
    "\n",
    "- In general, the higher power the less weight is given to extreme deviations between true and predicted targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "2500.0\n"
     ]
    }
   ],
   "source": [
    "# MSE (power=0): very sensitive to 2nd point's predict diff:\n",
    "from sklearn.metrics import mean_tweedie_deviance as MTD\n",
    "\n",
    "print(MTD([  1.0],   [1.5], power=0))\n",
    "print(MTD([100.0], [150.0], power=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18906978378367123\n",
      "18.906978378367114\n"
     ]
    }
   ],
   "source": [
    "# power=1\n",
    "print(MTD([  1.0],   [1.5], power=1))\n",
    "print(MTD([100.0], [150.0], power=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14426354954966225\n",
      "0.14426354954966225\n"
     ]
    }
   ],
   "source": [
    "# power=2\n",
    "print(MTD([  1.0],   [1.5], power=2))\n",
    "print(MTD([100.0], [150.0], power=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:working] *",
   "language": "python",
   "name": "conda-env-working-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
