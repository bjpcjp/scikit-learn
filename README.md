### scikit-learn v0.24.1

| Section | Title | Contents |
| ------- | ----- | -------- |
| 00      | **Getting Started** | Estimators, Transformers, Preprocessors, Pipelines, Model Evaluation, Parameter Searches, Next Steps |
| 01      | **Linear Models** | OLS, LS <br> Ridge <br> Lasso <br> Elastic-Net <br> Least Angle Regression (LARS) <br> LARS Lasso <br> OMP <br. Bayes <br> Generalized Linear Models (GLM) <br> Tweedie Models <br> Stochastic Gradient Descent (SGD) <br> Perceptrons <br> Passive-Aggressive Algos <br> RANSAC, Huber, Thiel-Sen <br> Polynomial Regression |
| 01a     | **Logistic Regression** | Basics, Examples |
| 02      | **Discriminant Analysis** | LDA <br> QDA <br> Math Foundations, Shrinkage, Estimators |
| 03 | **Kernel Ridge Regression** | KRR vs SVR |
| 04 | **Support Vector Machines (SVMs)** | Classifiers (SVC, NuSVC, LinearSVC), <br> Regressors (SVR, NuSVR, LinearSVR),<br> Scoring, Weights,  Complexity, Kernels |
| 05 | **Stochastic Gradient Descent (SGD)** | Classifier <br> Classifier (Multiclass) <br> Classifier (Weighted) <br> Solvers <br> Regressors <br> Sparse Data; Complexity; Stopping/Convergence; Tips |
| 06 | **K Nearest Neighbors (KNN)** | Algos (Ball Tree, KD Tree, Brute Force) <br> Radius-based Classifiers <br> Radius-based Regressors <br> Nearest Centroid Classifiers <br> Caching <br> Neighborhood Components Analysis (NCA) |
| 07 | **Gaussian Processes (GPs)** | GP Regressors |
| 08 | **Cross Decomposition** | Partial Least Squares (PLS) <br> Canonical PLS <br> SVD PLS <br> PLS Regression <br> Canonical Correlation Analysis (CCA) |
| 09 | **Naive Bayes (NB)** | Gaussian NB <br> Multinomial NB <br> Complement NB <br> Bernoulli NB <br> Categorical NB <br> Out-of-core fitting |
| 10 | **Decision Trees (DTs)** | Classifiers <br> Graphviz <br> Regressions <br> Multiple Outputs <br> Extra Trees <br> Complexity, Algorithms <br> Gini, Entropy, Misclassification <br> Minimal cost-complexity Pruning |
| 11a | **Ensembles/Bagging** | Methods <br> Random Forests, Extra Trees <br> Parameters, Parallel Execution, Feature Importance <br> Random Tree Embedding
| 11b | **Ensembles/Boosting** | AdaBoost <br> Gradient Boosting (GBs) <br> GB Classifiers <br> GB Regressions <br> Tree Sizes, Math (TODO), Loss Functions, Shrinkage, Subsampling, Feature Importance <br> Histogram Gradient Boosting (HGB) <br> HGB - Monotonic Constraints <br> Stacked Generalization |
| 11c | **Ensembles/Voting** | Hard Voting, Soft Voting, Voting Regressor |
| 11d | **Ensembles/General Stacking** | Summary |
| 12 | **Multiclass/Multioutput Problems** | Label Binarization <br> One vs Rest (OvR), One vs One (OvO) Classification <br> Output Codes <br> Multilabel, Multioutput Classification <br> Classifier Chains <br> Multioutput Regressions <br> Regression Chains |
| 13 | **Feature Selection (FS)** | Removing Low-Variance Features <br> Univariate FS <br> | Recursive FS | Model-based FS | Impurity-based FS | Sequential FS | Pipeline Usage |
| 14 | **Semi-Supervised/Unsupervised Learning** | Self-Training Classifier <br> Label Propagation, Label Spreading |
| 15 | **Isotonic Regression** | Example |
| 16 | **Calibration Curves** | Intro/Example, Cross-Validation, Metrics <br> Regressors |
| 17 | **Perceptrons** | Intro, Classification, Regression, Regularization, Training, Complexity, Tips |